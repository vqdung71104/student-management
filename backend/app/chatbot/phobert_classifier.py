"""
PhoBERT-based Intent Classifier cho tiáº¿ng Viá»‡t
Sá»­ dá»¥ng Sentence Transformers vá»›i model Vietnamese SBERT
"""
import json
import os
from typing import Dict, List, Tuple
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity


class PhoBERTIntentClassifier:
    """
    Intent classifier sá»­ dá»¥ng PhoBERT embeddings vá»›i semantic similarity
    """
    
    def __init__(self):
        """Initialize PhoBERT model vÃ  load intents"""
        print("ğŸ”„ Loading PhoBERT model...")
        
        # Sá»­ dá»¥ng Vietnamese SBERT model
        try:
            self.model = SentenceTransformer('keepitreal/vietnamese-sbert')
            print("âœ… Loaded Vietnamese SBERT model")
        except Exception as e:
            print(f"âš ï¸ Failed to load Vietnamese SBERT, using multilingual model: {e}")
            # Fallback to multilingual model
            self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        
        self.intents = self._load_intents()
        self.intent_embeddings = {}
        self._precompute_intent_embeddings()
        
        # Thresholds cho confidence levels
        self.thresholds = {
            "high": 0.65,      # Similarity > 0.65 = high confidence
            "medium": 0.45,    # Similarity > 0.45 = medium confidence
            "low": 0.0         # CÃ²n láº¡i = low confidence
        }
        
        print(f"âœ… PhoBERT classifier initialized with {len(self.intents.get('intents', []))} intents")
    
    def _load_intents(self) -> Dict:
        """Load intents tá»« file JSON"""
        intents_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "data",
            "intents.json"
        )
        
        try:
            with open(intents_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file intents.json táº¡i {intents_path}")
            return {"intents": []}
    
    def _precompute_intent_embeddings(self):
        """
        TÃ­nh trÆ°á»›c embeddings cho táº¥t cáº£ patterns trong má»—i intent
        Sá»­ dá»¥ng average embedding cho má»—i intent
        """
        print("ğŸ”„ Precomputing intent embeddings...")
        
        for intent in self.intents.get("intents", []):
            tag = intent["tag"]
            patterns = intent["patterns"]
            
            if not patterns:
                continue
            
            # Encode táº¥t cáº£ patterns
            patterns_embeddings = self.model.encode(
                patterns,
                convert_to_tensor=False,
                show_progress_bar=False
            )
            
            # TÃ­nh average embedding cho intent nÃ y
            avg_embedding = np.mean(patterns_embeddings, axis=0)
            
            self.intent_embeddings[tag] = {
                "embedding": avg_embedding,
                "patterns": patterns,
                "description": intent.get("description", "")
            }
        
        print(f"âœ… Precomputed embeddings for {len(self.intent_embeddings)} intents")
    
    async def classify_intent(self, user_message: str) -> Dict[str, any]:
        """
        PhÃ¢n loáº¡i intent cá»§a user message báº±ng semantic similarity
        
        Args:
            user_message: Tin nháº¯n tá»« user
            
        Returns:
            Dict vá»›i keys: intent, description, confidence, similarity_score
        """
        try:
            # Encode user message
            user_embedding = self.model.encode(
                [user_message],
                convert_to_tensor=False,
                show_progress_bar=False
            )[0]
            
            # TÃ­nh similarity vá»›i táº¥t cáº£ intents
            similarities = {}
            for intent_tag, intent_data in self.intent_embeddings.items():
                similarity = cosine_similarity(
                    [user_embedding],
                    [intent_data["embedding"]]
                )[0][0]
                
                similarities[intent_tag] = {
                    "score": float(similarity),
                    "description": intent_data["description"]
                }
            
            # TÃ¬m intent cÃ³ similarity cao nháº¥t
            best_intent = max(similarities.items(), key=lambda x: x[1]["score"])
            best_intent_tag = best_intent[0]
            best_score = best_intent[1]["score"]
            
            # XÃ¡c Ä‘á»‹nh confidence level
            if best_score >= self.thresholds["high"]:
                confidence = "high"
            elif best_score >= self.thresholds["medium"]:
                confidence = "medium"
            else:
                confidence = "low"
                best_intent_tag = "unknown"
            
            return {
                "intent": best_intent_tag,
                "description": similarities[best_intent_tag]["description"] if best_intent_tag != "unknown" else "Ã Ä‘á»‹nh khÃ´ng xÃ¡c Ä‘á»‹nh",
                "confidence": confidence,
                "similarity_score": best_score,
                "method": "phobert"
            }
            
        except Exception as e:
            print(f"âŒ Lá»—i khi phÃ¢n loáº¡i intent vá»›i PhoBERT: {str(e)}")
            return {
                "intent": "unknown",
                "description": "KhÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh Ã½ Ä‘á»‹nh",
                "confidence": "low",
                "similarity_score": 0.0,
                "method": "phobert",
                "error": str(e)
            }
    
    def get_all_similarities(self, user_message: str) -> List[Tuple[str, float]]:
        """
        Láº¥y similarity scores cho táº¥t cáº£ intents (Ä‘á»ƒ debugging)
        
        Returns:
            List of (intent_tag, similarity_score) sorted by score descending
        """
        user_embedding = self.model.encode(
            [user_message],
            convert_to_tensor=False,
            show_progress_bar=False
        )[0]
        
        similarities = []
        for intent_tag, intent_data in self.intent_embeddings.items():
            similarity = cosine_similarity(
                [user_embedding],
                [intent_data["embedding"]]
            )[0][0]
            
            similarities.append((intent_tag, float(similarity)))
        
        # Sort by similarity descending
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities
    
    def get_intent_friendly_name(self, intent_tag: str) -> str:
        """
        Chuyá»ƒn intent tag thÃ nh tÃªn dá»… hiá»ƒu cho ngÆ°á»i dÃ¹ng
        """
        intent_names = {
            "registration_guide": "hÆ°á»›ng dáº«n Ä‘Äƒng kÃ½ há»c pháº§n",
            "subject_registration_suggestion": "gá»£i Ã½ Ä‘Äƒng kÃ½ há»c pháº§n",
            "class_registration_suggestion": "gá»£i Ã½ Ä‘Äƒng kÃ½ lá»›p há»c",
            "view_grades": "xem káº¿t quáº£ há»c táº­p",
            "scholarship_info": "tÃ¬m hiá»ƒu thÃ´ng tin há»c bá»•ng",
            "schedule_inquiry": "tra cá»©u lá»‹ch há»c",
            "course_info": "há»i thÃ´ng tin mÃ´n há»c",
            "subject_info": "há»i thÃ´ng tin há»c pháº§n",
            "greeting": "chÃ o há»i",
            "thanks": "cáº£m Æ¡n",
            "unknown": "Ä‘áº·t cÃ¢u há»i"
        }
        
        return intent_names.get(intent_tag, "trao Ä‘á»•i")
