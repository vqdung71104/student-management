# Machine Learning Models

## âš ï¸ Important Note

Model files are **NOT** stored in Git repository due to large file sizes (>100MB).

## ğŸ“ Directory Structure

```
backend/models/
â”œâ”€â”€ README.md (this file)
â””â”€â”€ vit5_nl2sql/          # ViT5 NL2SQL model (ignored by Git)
    â”œâ”€â”€ best/
    â”‚   â”œâ”€â”€ config.json
    â”‚   â”œâ”€â”€ generation_config.json
    â”‚   â””â”€â”€ model.safetensors  # ~270MB - ignored
    â””â”€â”€ checkpoint-*/
```

## ğŸš€ How to Get Models

### Option 1: Train Your Own Model (Recommended)

```bash
cd backend
python scripts/train_vit5_nl2sql.py --epochs 10 --batch_size 4
```

This will:
- Download VietAI/vit5-base model (~1GB)
- Fine-tune on NL2SQL training data
- Save model to `backend/models/vit5_nl2sql/best/`

### Option 2: Download Pre-trained Model

If someone on your team has trained the model, ask them to share:
- Upload to cloud storage (Google Drive, Dropbox, etc.)
- Download and extract to `backend/models/vit5_nl2sql/`

## ğŸ”§ Using Without ViT5 Model

The NL2SQL system works **without** the ViT5 model using rule-based fallback:

- âœ… Rule-based approach: ~70-80% accuracy (works immediately)
- âœ… ViT5 model approach: >90% accuracy (requires training)

The system automatically detects if ViT5 model is available and falls back to rule-based if not.

## ğŸ“Š Model Details

**Model**: VietAI/vit5-base fine-tuned for Vietnamese NL2SQL

**Size**: ~270MB

**Training Data**: `backend/data/nl2sql_training_data.json` (25+ examples)

**Performance**:
- Accuracy: >90% on test queries
- Inference time: ~100-300ms per query
- Supports: 12 intent types

## ğŸ—‘ï¸ Ignored Files

The following files are ignored by Git (see `.gitignore`):

```
backend/models/vit5_nl2sql/
*.safetensors
*.bin
*.pth
*.pt
*.onnx
*.h5
*.keras
```

## ğŸ“ Notes

- Models are stored locally only
- Each developer needs to train or download models separately
- Use Git LFS if you want to version control models in the future
- Consider using model hosting services (Hugging Face, AWS S3, etc.) for team collaboration
